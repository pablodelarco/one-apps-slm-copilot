---
phase: 03-opennebula-integration
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - appliances/slm-copilot/appliance.sh
  - appliances/slm-copilot/slm-copilot-banner.sh
  - appliances/slm-copilot/marketplace.yaml
autonomous: true

must_haves:
  truths:
    - "cat /etc/one-appliance/config shows endpoint URL, credentials, model name, service status, and Cline JSON snippet"
    - "SSH login to the VM displays a banner showing service status and connection information"
    - "Marketplace metadata YAML contains European sovereign AI messaging, all context variable defaults, and correct image format"
  artifacts:
    - path: "appliances/slm-copilot/appliance.sh"
      provides: "write_report_file helper called from service_bootstrap, service_help updated with report/log/banner paths"
      contains: "write_report_file"
    - path: "appliances/slm-copilot/slm-copilot-banner.sh"
      provides: "SSH login banner script for /etc/profile.d/"
      contains: "SLM-Copilot -- Sovereign AI Coding Assistant"
    - path: "appliances/slm-copilot/marketplace.yaml"
      provides: "Community marketplace YAML metadata with European sovereign AI description"
      contains: "European Sovereign AI"
  key_links:
    - from: "service_bootstrap()"
      to: "write_report_file()"
      via: "called at end of bootstrap after services confirmed running"
      pattern: "write_report_file"
    - from: "service_install()"
      to: "slm-copilot-banner.sh"
      via: "copies banner script to /etc/profile.d/ during Packer build"
      pattern: "profile\\.d.*banner"
    - from: "write_report_file()"
      to: "/var/lib/slm-copilot/password"
      via: "reads plaintext password for report"
      pattern: "cat.*/var/lib/slm-copilot/password"
    - from: "write_report_file()"
      to: "ONE_SERVICE_REPORT"
      via: "writes INI-style report to framework-defined path"
      pattern: "ONE_SERVICE_REPORT"
---

<objective>
Implement the report file writer, Cline connection snippet, SSH login banner, and marketplace metadata YAML.

Purpose: Requirements ONE-02 (report file), ONE-05 (Cline snippet), ONE-06 (marketplace metadata with EU sovereign messaging), and ONE-08 (SSH banner) complete the OpenNebula integration layer. The report file is the primary user-facing artifact -- it tells the user how to connect. The banner provides the same info on SSH login. The marketplace YAML enables community submission.

Output: Updated appliance.sh with write_report_file helper and banner installation, new slm-copilot-banner.sh script, new marketplace.yaml file.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-opennebula-integration/03-RESEARCH.md
@.planning/phases/03-opennebula-integration/03-01-SUMMARY.md
@appliances/slm-copilot/appliance.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add write_report_file helper and SSH banner installation</name>
  <files>appliances/slm-copilot/appliance.sh, appliances/slm-copilot/slm-copilot-banner.sh</files>
  <action>
**A. Create the banner script file** at `appliances/slm-copilot/slm-copilot-banner.sh`:

```bash
#!/bin/bash
# /etc/profile.d/slm-copilot-banner.sh
# Displays SLM-Copilot service info on interactive SSH login

# Only print for interactive shells
[[ $- == *i* ]] || return

_vm_ip=$(hostname -I 2>/dev/null | awk '{print $1}')
_password=$(cat /var/lib/slm-copilot/password 2>/dev/null || echo 'see report')
_localai=$(systemctl is-active local-ai 2>/dev/null || echo 'unknown')
_nginx=$(systemctl is-active nginx 2>/dev/null || echo 'unknown')

printf '\n'
printf '  SLM-Copilot -- Sovereign AI Coding Assistant\n'
printf '  =============================================\n'
printf '  Endpoint : https://%s\n' "${_vm_ip}"
printf '  Username : copilot\n'
printf '  Password : %s\n' "${_password}"
printf '  Model    : devstral-small-2 (24B Q4_K_M)\n'
printf '  LocalAI  : %s\n' "${_localai}"
printf '  Nginx    : %s\n' "${_nginx}"
printf '\n'
printf '  Report   : cat /etc/one-appliance/config\n'
printf '  Logs     : tail -f /var/log/one-appliance/slm-copilot.log\n'
printf '\n'
```

This follows Research Pattern 3: use /etc/profile.d/ for dynamic banner (framework owns /etc/motd). The script runs on every interactive SSH login and queries live service status.

**B. Install the banner script in service_install()** -- add BEFORE the "Set ownership" step (before `chown -R`):

```bash
# Install SSH login banner (ONE-08)
install -m 0644 "$(dirname "$0")/slm-copilot-banner.sh" /etc/profile.d/slm-copilot-banner.sh
```

Note: `$(dirname "$0")` resolves to the appliance script's directory. If the one-apps framework sources the script differently (not via direct path), use a hardcoded path instead: `install -m 0644 /etc/one-appliance/service.d/slm-copilot-banner.sh /etc/profile.d/slm-copilot-banner.sh` or copy inline. Verify which approach works with the framework. If `$0` is unreliable, write the banner inline using a heredoc in service_install instead of copying from an external file. The inline heredoc approach is more robust for one-apps appliances.

Actually, prefer the INLINE HEREDOC approach (more reliable in one-apps context where the script is sourced, not executed directly):

```bash
# Install SSH login banner (ONE-08)
cat > /etc/profile.d/slm-copilot-banner.sh <<'BANNER_EOF'
#!/bin/bash
[[ $- == *i* ]] || return
_vm_ip=$(hostname -I 2>/dev/null | awk '{print $1}')
_password=$(cat /var/lib/slm-copilot/password 2>/dev/null || echo 'see report')
_localai=$(systemctl is-active local-ai 2>/dev/null || echo 'unknown')
_nginx=$(systemctl is-active nginx 2>/dev/null || echo 'unknown')
printf '\n'
printf '  SLM-Copilot -- Sovereign AI Coding Assistant\n'
printf '  =============================================\n'
printf '  Endpoint : https://%s\n' "${_vm_ip}"
printf '  Username : copilot\n'
printf '  Password : %s\n' "${_password}"
printf '  Model    : devstral-small-2 (24B Q4_K_M)\n'
printf '  LocalAI  : %s\n' "${_localai}"
printf '  Nginx    : %s\n' "${_nginx}"
printf '\n'
printf '  Report   : cat /etc/one-appliance/config\n'
printf '  Logs     : tail -f /var/log/one-appliance/slm-copilot.log\n'
printf '\n'
BANNER_EOF
chmod 0644 /etc/profile.d/slm-copilot-banner.sh
```

Still create the standalone `slm-copilot-banner.sh` file in the repo for reference/documentation, but the actual installation uses the inline heredoc.

**C. Add write_report_file() helper** to appliance.sh (new REPORT section, after the logging helpers):

Follow Research Pattern 2 exactly. The function:
1. Gets VM IP via `hostname -I | awk '{print $1}'`
2. Reads password from `/var/lib/slm-copilot/password` (NEVER from $ONEAPP_COPILOT_PASSWORD -- see Pitfall 3)
3. Determines TLS mode (self-signed vs letsencrypt) by checking if Let's Encrypt cert exists
4. Determines endpoint URL (domain if set, IP otherwise)
5. Queries live service status via `systemctl is-active`
6. Writes INI-style report to `${ONE_SERVICE_REPORT:-/etc/one-appliance/config}` (defensive fallback per Research)
7. Includes ALL sections: Connection info, Model, Service status, Cline VS Code setup, Cline JSON snippet, Test with curl
8. `chmod 600` the report file (contains password)
9. Logs via log_copilot

Use the report file template from Research Pattern 2 code example (lines 354-397 of 03-RESEARCH.md) as the authoritative template.

**D. Wire write_report_file into service_bootstrap()** -- call it at the END, after the `attempt_letsencrypt` call and before the final completion log line. This ensures service status fields reflect actual running state (Pitfall 2).

**E. Update service_help()** to add report file and log file paths to the help text:

Add after the "Configuration files:" section:
```
Report and logs:
  /etc/one-appliance/config                    Service report (credentials, Cline config)
  /var/log/one-appliance/slm-copilot.log       Application log (all stages)
```

**F. Shellcheck compliance** -- run shellcheck on both appliance.sh and slm-copilot-banner.sh. The banner script should have no warnings (variables are intentionally local with `_` prefix).
  </action>
  <verify>
- `bash -n appliances/slm-copilot/appliance.sh` passes
- `shellcheck appliances/slm-copilot/appliance.sh` shows zero warnings
- `shellcheck appliances/slm-copilot/slm-copilot-banner.sh` shows zero warnings (or acceptable SC-level disables)
- `grep 'write_report_file' appliances/slm-copilot/appliance.sh` shows function definition and call in service_bootstrap
- `grep 'ONE_SERVICE_REPORT' appliances/slm-copilot/appliance.sh` shows defensive usage with fallback
- `grep 'profile.d' appliances/slm-copilot/appliance.sh` shows banner installation in service_install
- `grep 'Cline JSON' appliances/slm-copilot/appliance.sh` shows JSON snippet in report file
  </verify>
  <done>
write_report_file helper exists and is called from service_bootstrap (after services running). Report includes endpoint, credentials, model, status, Cline setup instructions, JSON snippet, and curl test command. Banner script installed to /etc/profile.d/ during service_install. service_help updated with report/log paths. Both scripts pass shellcheck.

Requirements satisfied: ONE-02 (report file), ONE-05 (Cline snippet), ONE-08 (SSH banner).
  </done>
</task>

<task type="auto">
  <name>Task 2: Create marketplace metadata YAML with European sovereign AI messaging</name>
  <files>appliances/slm-copilot/marketplace.yaml</files>
  <action>
Create `appliances/slm-copilot/marketplace.yaml` following the community marketplace format from Research Pattern 6 and the marketplace-community README.

Use the YAML template from Research code example (lines 460-537 of 03-RESEARCH.md) as the authoritative template with these specifics:

1. **name:** `SLM-Copilot 1.0.0`
2. **version:** `1.0.0`
3. **publisher:** `OpenNebula Systems`
4. **description:** Use YAML literal block scalar (`|-`) with:
   - First paragraph: One-click sovereign AI coding assistant intro
   - Second paragraph: European Sovereign AI messaging (Mistral Paris, OpenNebula Madrid, Apache 2.0)
   - Third paragraph: VS Code + Cline integration description
   - Fourth paragraph: Feature bullet list (API, HTTPS, Let's Encrypt, auth, context vars, report file, idempotent)
5. **short_description:** Use YAML folded block scalar (`>-`) for single-line
6. **tags:** ai, llm, coding, copilot, sovereign, cpu, localai, devstral, cline, ubuntu
7. **format:** qcow2
8. **os-id/os-release/os-arch:** Ubuntu, 24.04 LTS, x86_64
9. **hypervisor:** KVM
10. **opennebula_version:** `6.10, 7.0`
11. **opennebula_template:** Include CONTEXT with all 4 ONEAPP_COPILOT_* vars and their defaults, CPU: 16, MEMORY: 32768, CPU_MODEL host-passthrough, GRAPHICS VNC, NIC with service network
12. **images:** Single OS image entry with PLACEHOLDER checksums (Phase 4 fills these in after Packer build)
13. **logo:** `slm-copilot.png` (placeholder -- actual logo added in Phase 4)

The messaging MUST include the key phrases from PROJECT.md:
- "Not all AI needs GPU"
- "100% sovereign" / "European Sovereign AI"
- "100% open-source"
- "One-click deployment"
- "Apache 2.0" license references

Validate the YAML file is syntactically correct. If `python3 -c "import yaml; yaml.safe_load(open('...'))"` is available, use it. Otherwise use visual inspection that all indentation is consistent (2-space).
  </action>
  <verify>
- File exists at `appliances/slm-copilot/marketplace.yaml`
- `python3 -c "import yaml; yaml.safe_load(open('appliances/slm-copilot/marketplace.yaml'))"` succeeds (if python3+yaml available), OR manual inspection confirms valid YAML
- `grep 'European Sovereign AI' appliances/slm-copilot/marketplace.yaml` finds the messaging
- `grep 'ONEAPP_COPILOT' appliances/slm-copilot/marketplace.yaml` shows all 4 context variables
- `grep 'PLACEHOLDER' appliances/slm-copilot/marketplace.yaml` shows checksum placeholders (to be filled in Phase 4)
  </verify>
  <done>
marketplace.yaml exists with complete community marketplace format, European sovereign AI messaging, all 4 context variable defaults in opennebula_template, PLACEHOLDER checksums for Phase 4, and valid YAML syntax. Requirement ONE-06 satisfied.
  </done>
</task>

</tasks>

<verification>
Phase 3 Plan 02 verification:
1. `bash -n appliances/slm-copilot/appliance.sh` -- syntax valid
2. `shellcheck appliances/slm-copilot/appliance.sh` -- zero warnings
3. `grep -c 'write_report_file' appliances/slm-copilot/appliance.sh` -- function defined AND called
4. `grep 'ONE_SERVICE_REPORT' appliances/slm-copilot/appliance.sh` -- shows defensive fallback pattern
5. `grep 'profile.d' appliances/slm-copilot/appliance.sh` -- shows banner installation
6. `grep 'Cline' appliances/slm-copilot/appliance.sh` -- shows Cline config in report
7. File exists: `appliances/slm-copilot/slm-copilot-banner.sh`
8. File exists: `appliances/slm-copilot/marketplace.yaml`
9. marketplace.yaml contains "European Sovereign AI" and all 4 ONEAPP_COPILOT_* defaults
</verification>

<success_criteria>
- write_report_file() exists and produces INI-style report at $ONE_SERVICE_REPORT with: endpoint, credentials, model, status, Cline setup, JSON snippet, curl test
- Report written in service_bootstrap AFTER services confirmed running (not in service_configure)
- Password read from /var/lib/slm-copilot/password, never from $ONEAPP_COPILOT_PASSWORD
- SSH banner script installed to /etc/profile.d/ in service_install, shows live service status on login
- marketplace.yaml is valid YAML with European sovereign AI messaging and complete opennebula_template
- All scripts pass shellcheck with zero warnings
- Requirements ONE-02, ONE-05, ONE-06, ONE-08 satisfied
- Combined with Plan 03-01: ALL 8 ONE requirements (ONE-01 through ONE-08) complete
</success_criteria>

<output>
After completion, create `.planning/phases/03-opennebula-integration/03-02-SUMMARY.md`
</output>
