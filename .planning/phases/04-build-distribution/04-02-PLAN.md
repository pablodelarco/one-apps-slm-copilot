---
phase: 04-build-distribution
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - test.sh
autonomous: true

must_haves:
  truths:
    - "Running `./test.sh <endpoint> <password>` validates 7 checks against a running SLM-Copilot instance and reports pass/fail for each"
    - "The test script validates HTTPS connectivity, health endpoint, auth rejection, auth acceptance, model listing, chat completion, and streaming SSE"
    - "All bash scripts in the repository pass shellcheck with zero warnings"
  artifacts:
    - path: "test.sh"
      provides: "Post-deployment test script with 7 validation checks and pass/fail reporting"
      contains: "SLM-Copilot Post-Deployment Test"
  key_links:
    - from: "Makefile test target"
      to: "test.sh"
      via: "make test ENDPOINT=... PASSWORD=... calls ./test.sh"
      pattern: "\\./test\\.sh"
    - from: "test.sh"
      to: "HTTPS endpoint /readyz"
      via: "curl -sk health check"
      pattern: "/readyz"
    - from: "test.sh"
      to: "HTTPS endpoint /v1/chat/completions"
      via: "curl -sk with basic auth for chat completion and streaming"
      pattern: "/v1/chat/completions"
---

<objective>
Create the post-deployment test script that validates a running SLM-Copilot instance, and ensure all bash scripts pass shellcheck.

Purpose: Requirement BUILD-03 (post-deployment test) provides operators with a single command to verify their deployment works correctly. Requirement BUILD-07 (shellcheck compliance) ensures all scripts are free of common bash pitfalls. Together these deliver confidence that the built image works as expected.

Output: test.sh with 7 validation checks and pass/fail summary. All existing and new scripts passing shellcheck.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-build-distribution/04-RESEARCH.md
@appliances/slm-copilot/appliance.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create post-deployment test script with 7 validation checks</name>
  <files>test.sh</files>
  <action>
Create `test.sh` at the project root following 04-RESEARCH.md Pattern 5 (Post-Deployment Test Script) and the code example (lines 592-692).

The script must:

1. Start with `#!/usr/bin/env bash` and `set -euo pipefail`
2. Accept two positional arguments: `ENDPOINT` and `PASSWORD`. Print usage if missing: `Usage: $0 <endpoint> <password>`.
3. Define constants: `USERNAME="copilot"`, `MODEL="devstral-small-2"`, `TIMEOUT=120` (generous for CPU inference).
4. Track results with `_pass`, `_fail`, `_total` counters.
5. Define `report()` function that increments counters and prints `[PASS]` or `[FAIL]` with test name.

6. Print header:
```
SLM-Copilot Post-Deployment Test
=================================
Endpoint: ${ENDPOINT}
```

7. Run 7 tests using `curl -sk` (insecure for self-signed certs):

   **Test 1: HTTPS connectivity** -- `curl -sk --max-time 10 -o /dev/null -w '%{http_code}'` to `${ENDPOINT}/`. Expect HTTP 401, 200, or 301 (any response proves HTTPS is working).

   **Test 2: Health endpoint** -- `curl -sk --max-time 10 "${ENDPOINT}/readyz"`. Expect response containing "ok" or "ready" (case-insensitive grep).

   **Test 3: Auth rejection** -- `curl -sk --max-time 10 -o /dev/null -w '%{http_code}' "${ENDPOINT}/v1/models"` WITHOUT credentials. Expect HTTP 401.

   **Test 4: Auth acceptance** -- `curl -sk --max-time 10 -u "${USERNAME}:${PASSWORD}" -o /dev/null -w '%{http_code}' "${ENDPOINT}/v1/models"` WITH credentials. Expect HTTP 200.

   **Test 5: Model listing** -- Parse JSON from models endpoint: `curl -sk --max-time 10 -u "${USERNAME}:${PASSWORD}" "${ENDPOINT}/v1/models"`. Use `jq -e ".data[] | select(.id == \"${MODEL}\")"` to verify the model is listed.

   **Test 6: Chat completion (non-streaming)** -- POST to `/v1/chat/completions` with auth, Content-Type JSON, body `{"model":"${MODEL}","messages":[{"role":"user","content":"Say hello in one word"}],"max_tokens":10}`. Use `--max-time ${TIMEOUT}`. Parse response with `jq -e '.choices[0].message.content'`.

   **Test 7: Streaming SSE** -- POST to `/v1/chat/completions` with `"stream":true` and `"max_tokens":5`. Use `--max-time ${TIMEOUT}`. Grep for `data:` in output to confirm SSE delivery.

8. Print summary: `Result: ${_pass}/${_total} tests passed`
9. Exit 1 if any test failed, exit 0 if all passed.

Important implementation notes:
- All curl calls use `-sk` (silent errors + insecure TLS for self-signed certs)
- Chat completion tests use `--max-time ${TIMEOUT}` (120s) because CPU inference is slow
- Each test is independent -- a failure in one test does NOT skip subsequent tests (use `if/else`, not `set -e` traps)
- Use `2>/dev/null` on jq commands to suppress parse errors for FAIL cases
- The script does NOT deploy VMs -- it tests an already-running instance

Make the script executable (`chmod +x test.sh`).
  </action>
  <verify>
- `test.sh` exists at project root and is executable
- `shellcheck test.sh` passes with zero warnings
- `bash -n test.sh` passes
- `grep -c 'report' test.sh` shows at least 7 report calls (one per test)
- `grep 'curl -sk' test.sh` shows all curl calls use insecure flag
- `grep 'max-time' test.sh` shows timeout on all curl calls
- `grep '/readyz' test.sh` shows health check test
- `grep '/v1/chat/completions' test.sh` shows chat completion tests
- `grep 'stream.*true' test.sh` shows streaming test
- `grep 'exit 1' test.sh` shows failure exit
  </verify>
  <done>
test.sh validates 7 checks against a running instance: HTTPS connectivity, health endpoint, auth rejection, auth acceptance, model listing, chat completion (non-streaming), and chat completion (streaming SSE). Uses curl -sk for self-signed certs with generous timeouts for CPU inference. Reports pass/fail for each test with summary count. Exits 0 on all-pass, 1 on any failure.

Requirements addressed: BUILD-03 (post-deployment test validates HTTPS, auth, health, model, chat, streaming).
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify shellcheck compliance for all scripts</name>
  <files>test.sh</files>
  <action>
Run shellcheck on ALL bash scripts in the repository and fix any warnings:

1. `shellcheck -x appliances/slm-copilot/appliance.sh` -- should already pass from Phase 3
2. `shellcheck -x test.sh` -- must pass (fix any issues from Task 1)
3. `shellcheck -x build.sh` -- must pass (created in 04-01, verify here)
4. `shellcheck -x build/packer/scripts/*.sh` -- must pass (created in 04-01, verify here)

For any warnings found:
- Fix quoting issues (always use `"${var}"`)
- Fix unused variable warnings (remove or use `# shellcheck disable=SC2034` with comment)
- Fix subshell issues (use `$()` not backticks)
- Ensure `set -euo pipefail` is present in all scripts

If 04-01 scripts are not yet created (different execution order), only verify test.sh and appliance.sh here. The lint target in the Makefile will catch any remaining issues.

This task primarily ensures test.sh itself passes shellcheck and verifies the overall shellcheck compliance posture. The `make lint` target provides ongoing enforcement.
  </action>
  <verify>
- `shellcheck -x appliances/slm-copilot/appliance.sh` exits 0
- `shellcheck -x test.sh` exits 0
- If build.sh exists: `shellcheck -x build.sh` exits 0
- If build/packer/scripts/*.sh exist: `shellcheck -x build/packer/scripts/*.sh` exits 0
  </verify>
  <done>
All bash scripts in the repository pass shellcheck with zero warnings. test.sh is shellcheck-clean. The make lint target in the Makefile (from 04-01) provides ongoing enforcement for future changes.

Requirements addressed: BUILD-07 (all bash scripts pass shellcheck with no warnings).
  </done>
</task>

</tasks>

<verification>
Phase 4 Plan 02 verification:
1. `ls test.sh` -- test script exists
2. `test -x test.sh` -- test script is executable
3. `shellcheck -x test.sh` -- passes with zero warnings
4. `shellcheck -x appliances/slm-copilot/appliance.sh` -- still passes
5. `grep -c '\[PASS\]\|\[FAIL\]' test.sh` -- shows test reporting
6. `grep 'SLM-Copilot Post-Deployment Test' test.sh` -- shows header
7. `grep '/v1/chat/completions' test.sh` -- shows API validation
</verification>

<success_criteria>
- test.sh validates 7 distinct checks: HTTPS connectivity, health, auth rejection, auth acceptance, model listing, chat completion, streaming
- Each test reports [PASS] or [FAIL] with descriptive name
- Summary shows pass/fail count, script exits 1 on any failure
- All curl calls use -sk for self-signed cert compatibility
- Chat completion tests use generous timeout (120s) for CPU inference
- All bash scripts in repository pass shellcheck with zero warnings
- BUILD-03 and BUILD-07 satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/04-build-distribution/04-02-SUMMARY.md`
</output>
