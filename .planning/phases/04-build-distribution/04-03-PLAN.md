---
phase: 04-build-distribution
plan: 03
type: execute
wave: 2
depends_on: ["04-01", "04-02"]
files_modified:
  - README.md
  - appliances/slm-copilot/marketplace.yaml
autonomous: true

must_haves:
  truths:
    - "README.md documents architecture, quick start, all ONEAPP_* variables, Cline connection setup with JSON snippet, troubleshooting steps, and performance expectations"
    - "README.md includes a manual build guide section describing step-by-step QCOW2 creation without Packer"
    - "marketplace.yaml checksums note says to update after successful build with actual values"
    - "A developer can follow the README to build the image (make build), deploy it, configure Cline, and validate with make test"
  artifacts:
    - path: "README.md"
      provides: "Complete documentation: architecture, quick start, configuration, Cline setup, manual build, troubleshooting, performance"
      contains: "SLM-Copilot"
    - path: "appliances/slm-copilot/marketplace.yaml"
      provides: "Marketplace YAML with updated creation_time and build instructions comment"
      contains: "PLACEHOLDER"
  key_links:
    - from: "README.md Quick Start"
      to: "make build"
      via: "documents build command and prerequisites"
      pattern: "make build"
    - from: "README.md Test section"
      to: "make test"
      via: "documents test command with ENDPOINT and PASSWORD"
      pattern: "make test"
    - from: "README.md Cline section"
      to: "VS Code settings.json"
      via: "JSON snippet for Cline OpenAI provider configuration"
      pattern: "cline.*settings"
    - from: "README.md Manual Build"
      to: "build/packer/ files"
      via: "references Packer steps that manual build replicates"
      pattern: "service install"
---

<objective>
Write the complete README documentation with architecture diagram, quick start, configuration reference, Cline setup guide, manual build guide, troubleshooting, and performance expectations. Finalize the marketplace YAML metadata.

Purpose: Requirements BUILD-04 (manual build guide), BUILD-08 (complete README), and BUILD-02 (marketplace YAML finalization) deliver the documentation layer. The README is the primary onboarding document -- a new user reads it and knows how to build, deploy, configure, connect, and troubleshoot.

Output: README.md with all sections, updated marketplace.yaml with build instructions comment.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-build-distribution/04-RESEARCH.md
@.planning/phases/04-build-distribution/04-01-SUMMARY.md
@.planning/phases/04-build-distribution/04-02-SUMMARY.md
@appliances/slm-copilot/appliance.sh
@appliances/slm-copilot/marketplace.yaml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write complete README documentation</name>
  <files>README.md</files>
  <action>
Create `README.md` at the project root. This is the primary documentation artifact. Structure it for a developer who has never seen the project before.

**Required sections (in order):**

**1. Title and badges**
```markdown
# SLM-Copilot: Sovereign AI Coding Assistant for OpenNebula
```
One-line description: "One-click deployment of a sovereign, CPU-only AI coding copilot from the OpenNebula marketplace."

**2. Overview** (2-3 paragraphs)
- What it is: OpenNebula marketplace appliance, LocalAI + Devstral Small 2 24B on CPU, Nginx with TLS + auth
- Key value: no GPU required, 100% sovereign (European open-source), one-click deployment
- How it works: import from marketplace, instantiate VM, connect from VS Code with Cline
- Mention: 100% open-source stack (Apache 2.0 model + MIT inference + BSD proxy + Apache 2.0 cloud)

**3. Architecture** (ASCII diagram + description)
ASCII diagram showing:
```
Developer Machine          OpenNebula VM (32 GB RAM, 16 vCPU)
+------------------+       +----------------------------------------+
| VS Code + Cline  | HTTPS | Nginx (TLS + Auth + CORS)  :443       |
|  OpenAI Provider |------>|   |                                    |
+------------------+       |   v                                    |
                           | LocalAI (llama-cpp)         :8080      |
                           |   |                                    |
                           |   v                                    |
                           | Devstral Small 2 (24B Q4_K_M, 14 GB)  |
                           +----------------------------------------+
```
Brief description of each component and data flow.

**4. Quick Start**
Prerequisites: OpenNebula 6.10+ with KVM, VM template with 32 GB RAM / 16 vCPU / 50 GB disk.

Steps:
1. Import the appliance from the marketplace (or build with `make build`)
2. Create a VM from the template, optionally setting ONEAPP_* context variables
3. Wait for boot (~2 min for service startup)
4. SSH in and check `cat /etc/one-appliance/config` for connection details
5. Connect from VS Code (see Cline Setup below)
6. Validate with `make test ENDPOINT=https://<vm-ip> PASSWORD=<password>`

**5. Configuration (ONEAPP_* Variables)**
Table format:

| Variable | Default | Description |
|----------|---------|-------------|
| `ONEAPP_COPILOT_PASSWORD` | (auto-generated) | API password for basic auth. If empty, a random 16-char password is generated. |
| `ONEAPP_COPILOT_DOMAIN` | (empty) | FQDN for Let's Encrypt certificate. If empty, uses self-signed cert with VM IP. |
| `ONEAPP_COPILOT_CONTEXT_SIZE` | 32768 | Token context window size (512-131072). Larger values use more RAM. |
| `ONEAPP_COPILOT_THREADS` | 0 (auto-detect) | CPU threads for inference. 0 = auto-detect all available cores. |

Note about context size vs RAM tradeoff.

**6. Cline Setup (VS Code)**
Step-by-step:
1. Install the Cline extension in VS Code
2. Open Cline settings (gear icon)
3. Select "OpenAI Compatible" as the API provider
4. Configure with the JSON snippet:
```json
{
  "cline.apiProvider": "openai-compatible",
  "cline.openAiCompatible.apiUrl": "https://<vm-ip>",
  "cline.openAiCompatible.apiKey": "<password>",
  "cline.openAiCompatible.modelId": "devstral-small-2"
}
```
5. Note: If using self-signed certs, the VS Code Cline extension should work as it typically does not verify TLS certificates for custom endpoints. If issues occur, the report file on the VM provides the exact configuration.

**7. Building from Source**
Prerequisites: Packer v1.15+, QEMU/KVM, cloud-image-utils (for cloud-localds), ~30 GB free disk, internet access.

```bash
git clone <repo-url>
cd demo-ga
make build
```

Build process overview: downloads Ubuntu 24.04 cloud image, clones one-apps, runs Packer (cloud-init ISO + QEMU provisioner with 8-step sequence), compresses QCOW2, generates checksums.

Build output: `build/export/slm-copilot-1.0.0.qcow2` (~15-18 GB compressed)

Build time: 20-40 minutes (depends on network speed for 14 GB model download and CPU for pre-warming).

Other targets: `make clean`, `make checksum`, `make lint`.

**8. Manual Build Guide (without Packer)**
Follow 04-RESEARCH.md Pattern 8. Document the 12 steps:
1. Download Ubuntu 24.04 cloud image
2. Create VM (4 vCPU, 16 GB RAM, 50 GB disk)
3. Boot and SSH in as root
4. Harden SSH (disable password auth)
5. Install one-context package
6. Create one-appliance directory structure
7. Install one-apps framework files (service.sh, common.sh, functions.sh, context hooks)
8. Copy appliance.sh to /etc/one-appliance/service.d/
9. Configure context hooks (move net-90, net-99 scripts)
10. Run `/etc/one-appliance/service install` (downloads LocalAI, model, pre-warms -- takes 15-30 min)
11. Cleanup: purge cloud-init, clear apt cache, truncate machine-id
12. Shutdown, export QCOW2, compress with `qemu-img convert -c -O qcow2`

**9. Testing**
```bash
make test ENDPOINT=https://<vm-ip> PASSWORD=<password>
```
Explain the 7 tests and expected output. Mention `-k` for self-signed certs.

**10. Troubleshooting**
Common issues with solutions:
- "Service not starting after boot" -- check `systemctl status local-ai`, `journalctl -u local-ai`, check RAM
- "Slow inference" -- expected 5-15 tok/s on CPU, increase threads, reduce context size
- "Let's Encrypt failed" -- check DNS, port 80 open, falls back to self-signed (not an error)
- "Out of memory" -- 24B model needs ~14 GB, context window adds KV cache, reduce ONEAPP_COPILOT_CONTEXT_SIZE
- "Cline can't connect" -- check HTTPS, verify password from `cat /etc/one-appliance/config`, check firewall port 443
- Log locations: `/var/log/one-appliance/slm-copilot.log` and `journalctl -u local-ai`

**11. Performance**
Table with expected performance on different hardware:

| vCPUs | RAM | Context Size | Approx. Speed |
|-------|-----|-------------|---------------|
| 8 | 32 GB | 32K | ~3-5 tok/s |
| 16 | 32 GB | 32K | ~5-10 tok/s |
| 32 | 64 GB | 64K | ~10-15 tok/s |

Note: AVX-512 support significantly improves inference speed. Context size affects memory usage (larger context = more RAM for KV cache).

**12. Marketplace Submission**
Brief instructions for submitting to marketplace-community:
1. Build image and generate checksums
2. Upload QCOW2 to hosting (CDN, S3, etc.)
3. Update `appliances/slm-copilot/marketplace.yaml` with actual URL and checksums
4. Rename file to UUID (`uuidgen`) for marketplace PR
5. Submit PR to marketplace-community repository

**13. License**
Apache 2.0 for the appliance. Component licenses: Apache 2.0 (Devstral model), MIT (LocalAI), BSD (Nginx), Apache 2.0 (OpenNebula one-apps).

**14. Author**
Pablo del Arco, Cloud-Edge Innovation Engineer at OpenNebula Systems.
  </action>
  <verify>
- `README.md` exists at project root
- `grep 'SLM-Copilot' README.md` shows title
- `grep 'ONEAPP_COPILOT' README.md` shows all 4 context variables documented
- `grep 'Cline' README.md` shows VS Code setup section
- `grep 'make build' README.md` shows build instructions
- `grep 'make test' README.md` shows test instructions
- `grep 'Manual Build' README.md` shows manual build guide section
- `grep 'Troubleshooting' README.md` shows troubleshooting section
- `grep 'Performance' README.md` shows performance expectations
- `grep 'sovereign' README.md` shows sovereignty messaging
- `wc -l README.md` shows substantial documentation (300+ lines expected)
  </verify>
  <done>
README.md documents the complete project: architecture with ASCII diagram, quick start for OpenNebula deployment, all 4 ONEAPP_* variables with defaults and descriptions, Cline VS Code setup with JSON snippet, building from source with make build, 12-step manual build guide without Packer, testing with make test, troubleshooting for 6 common issues, performance expectations table, marketplace submission steps, and license information.

Requirements addressed: BUILD-04 (manual build guide), BUILD-08 (complete README with architecture, quick start, config, Cline setup, troubleshooting, performance).
  </done>
</task>

<task type="auto">
  <name>Task 2: Finalize marketplace YAML metadata</name>
  <files>appliances/slm-copilot/marketplace.yaml</files>
  <action>
Update the existing `appliances/slm-copilot/marketplace.yaml` (created in Phase 3, plan 03-02) with minor refinements for Phase 4 completion:

1. **Add a comment block at the top** (before the `---` frontmatter delimiter or at the top of the YAML) explaining how to finalize for marketplace submission:
```yaml
# SLM-Copilot Marketplace Metadata
#
# After a successful build, update these PLACEHOLDER values:
#   1. images[0].url     -- Replace PUBLISH_URL with actual hosting URL
#   2. images[0].checksum.md5  -- From: md5sum build/export/slm-copilot-1.0.0.qcow2
#   3. images[0].checksum.sha256 -- From: sha256sum build/export/slm-copilot-1.0.0.qcow2
#   4. images[0].size    -- From: qemu-img info --output=json ... | jq '.["virtual-size"]'
#   5. Rename this file to a UUID for marketplace PR: mv marketplace.yaml $(uuidgen).yaml
```

2. **Update `creation_time`** to current epoch (Feb 14 2026 = 1739500800 -- keep existing value, it's correct for the creation date).

3. **Verify all fields are correct** against the marketplace-community format:
   - `name`, `version`, `publisher` present
   - `description` with sovereign AI messaging
   - `short_description` present
   - `tags` array present
   - `format: qcow2`
   - `creation_time` as epoch integer
   - `os-id`, `os-release`, `os-arch` present
   - `hypervisor: KVM`
   - `opennebula_version` present
   - `opennebula_template` with CONTEXT (all 4 ONEAPP_* vars), CPU, MEMORY, CPU_MODEL, GRAPHICS, NIC
   - `images` array with single entry containing `name`, `url`, `type`, `dev_prefix`, `driver`, `size`, `checksum`

4. **Ensure PLACEHOLDER values are clearly marked** so the build process (or operator) knows what to replace.

The marketplace YAML is already substantially complete from Phase 3. This task adds build-instruction comments and performs a final validation pass.
  </action>
  <verify>
- `head -10 appliances/slm-copilot/marketplace.yaml` shows instruction comments
- `grep 'PLACEHOLDER' appliances/slm-copilot/marketplace.yaml` shows checksum placeholders
- `grep 'PUBLISH_URL' appliances/slm-copilot/marketplace.yaml` shows URL placeholder
- `python3 -c "import yaml; yaml.safe_load(open('appliances/slm-copilot/marketplace.yaml'))" 2>/dev/null` or manual inspection confirms valid YAML
- `grep 'European Sovereign AI' appliances/slm-copilot/marketplace.yaml` shows messaging preserved
- `grep 'ONEAPP_COPILOT' appliances/slm-copilot/marketplace.yaml` shows all 4 context variables
  </verify>
  <done>
marketplace.yaml is finalized with instruction comments explaining how to fill PLACEHOLDER values after a successful build (URL, checksums, size, UUID rename). All existing fields preserved (European sovereign AI messaging, opennebula_template, context variables). YAML syntax validated. Ready for PR submission after first successful build provides real checksums.

Requirements addressed: BUILD-02 (community marketplace YAML follows marketplace-community format, ready for submission).
  </done>
</task>

</tasks>

<verification>
Phase 4 Plan 03 verification:
1. `ls README.md` -- README exists
2. `wc -l README.md` -- substantial documentation (300+ lines)
3. `grep -c 'ONEAPP_COPILOT' README.md` -- all 4 variables documented
4. `grep 'Manual Build' README.md` -- manual build section present
5. `grep 'Cline' README.md` -- Cline setup documented
6. `grep 'make build' README.md` -- build command documented
7. `grep 'make test' README.md` -- test command documented
8. `head -10 appliances/slm-copilot/marketplace.yaml` -- instruction comments present
9. `grep 'PLACEHOLDER' appliances/slm-copilot/marketplace.yaml` -- placeholders for post-build update
</verification>

<success_criteria>
- README.md is comprehensive: architecture, quick start, configuration, Cline setup, build from source, manual build, testing, troubleshooting, performance, marketplace, license
- README includes JSON snippet for Cline VS Code configuration
- README includes manual build guide with 12 steps (BUILD-04)
- README includes all 4 ONEAPP_* variables with defaults and descriptions
- marketplace.yaml has build-instruction comments for PLACEHOLDER replacement
- marketplace.yaml remains valid YAML with all required fields
- A new developer can follow the README end-to-end: build, deploy, connect, test
- BUILD-02, BUILD-04, BUILD-08 satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/04-build-distribution/04-03-SUMMARY.md`
</output>
